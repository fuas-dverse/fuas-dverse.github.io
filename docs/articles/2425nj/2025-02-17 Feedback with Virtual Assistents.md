---
tags:
  - Article
---
# How AI Can Help Students with Research: The Future of Virtual Agents in Education

*by Oliver Paszkiewicz*

In today’s fast-moving digital world, students rely more than ever on technology to assist them in their academic work. But while search engines and online resources are helpful, they often fall short in providing personalized guidance for complex tasks—like conducting a literature review. That’s where artificial intelligence (AI) comes in.

Our latest research explores how AI-powered virtual agents can support students during problem-solving activities, particularly in conducting literature reviews. This study examines how students interact with virtual assistants, what types of feedback are most useful, and how AI interfaces can be designed for maximum efficiency.

## Why Does This Matter?

Literature reviews are essential for academic research, but they can be overwhelming, especially for students unfamiliar with the process. Searching for relevant sources, evaluating credibility, and organizing information require both time and expertise. A well-designed AI assistant can make this process smoother, offering structured guidance, personalized feedback, and real-time collaboration.

The goal of this research was to determine the most effective ways for students to interact with AI while keeping them in control of their learning. Rather than replacing human effort, the virtual agent is designed to complement students’ thinking, providing guidance when needed and allowing for independent decision-making.

## How Did We Study AI and Student Interactions?

To test how students respond to AI support, we used a method called the **Wizard of Oz experiment**—a technique where users interact with what they believe is an AI system, but in reality, a human is providing the responses behind the scenes. This allowed us to simulate a highly intelligent virtual assistant and assess what students found helpful.

A small group of undergraduate students participated in the study, completing a literature review with the help of the AI assistant. They interacted with the system through a messaging platform, receiving advice on:

- How to read a scientific paper
- Key terms to focus on
- Where to find relevant information

After the session, students were interviewed to gather feedback on their experiences.

## What Did We Learn?

Our findings highlighted several key takeaways:

1. **Students Prefer Clear and Direct Guidance**
	- The most valued type of feedback was **Localization Feedback**, where the AI assistant pointed students directly to relevant sources.
	- **Direct Feedback**, which explained why a source was useful, was also highly appreciated.
2. **Customization and Control Are Important**
	- We tested two types of AI interfaces: a **movable widget** and a **fixed sidebar**.
	- Students preferred the movable widget because it allowed them to reposition it as needed, making it less intrusive.
3. **Students Want AI to Support—Not Replace—Their Thinking**
	- While AI was helpful in guiding the literature review, students emphasized the importance of making their own decisions rather than relying entirely on the AI’s suggestions.

## The Future of AI in Education

Our research contributes to the growing field of human-AI collaboration, offering insights into how virtual agents can be designed to support learning. The key takeaway is that AI should be a **learning partner**, not just an answer provider.

To further improve AI-powered educational tools, we recommend:

- **Developing adaptive AI that adjusts to individual student needs**
- **Ensuring AI recommendations are transparent and well-explained**
- **Providing students with control over AI interactions**

Although our study focused on a small group of students, it sets the stage for future research into AI’s role in education. With continuous improvements, AI can become a valuable assistant for students worldwide, making research and learning more efficient and accessible.
